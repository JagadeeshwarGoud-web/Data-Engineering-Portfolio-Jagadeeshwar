# Data Engineering Portfolio â€” Kurra Jagadeeshwar Goud

Welcome to my Data Engineering portfolio!  
This repository showcases hands-on projects built using modern data engineering tools and cloud platforms.

## Tech Stack
Python | SQL | Apache Spark | Airflow | dbt | AWS | Azure | Databricks | Redshift | Kafka | Great Expectations

## Projects
| No | Project Name | Description | Technologies |
|----|--------------|-------------|--------------|
| 1 | **E-commerce ETL & Data Warehouse** | Automated ETL pipeline using Airflow and Redshift with dbt transformations | Python, Airflow, AWS S3, Redshift, dbt |
| 2 | **Real-time Clickstream Pipeline** | Streaming data pipeline for user event analytics | Kafka, Spark, PostgreSQL |
| 3 | **Data Lakehouse Proof-of-Concept** | Lakehouse integration with Glue and Spark | AWS S3, Glue, Spark, BigQuery |
| 4 | **Automated Data Quality Framework** | Validation framework using Great Expectations | Python, Airflow, Great Expectations |

## Goal
To demonstrate my hands-on skills in designing scalable, reliable, and production-ready data pipelines used in modern analytics and AI ecosystems.

## Author
**Kurra Jagadeeshwar Goud**  
ðŸ“§ kurrajagadeeshwargoud@gmail.com  
ðŸ”— https://linkedin.com/in/jagadeeshwar-goud-kurra

